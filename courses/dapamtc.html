<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
  <title>Data-aware parallel algorithms for matrix and tensor computations</title>
  <link rel="stylesheet" href="anne.css" />
</head>
<body bgcolor="#ffffff" text="#000000">

<center><h1 class="title">Data-aware parallel algorithms for matrix and tensor computations</h1></center>
<center><h3>Instructor: <a href="https://surakuma.github.io/">Suraj Kumar</a>, Fall 2023 </h3></center><br><br>

<!--
<h1>Data-aware parallel algorithms for matrix and tensor computations</h1>

<h4>Instructor: <a href="https://surakuma.github.io/">Suraj Kumar</a>, Fall 2023 </h4>

<i>Course notes and slides:</i>
-->


<p>
In the last few decades, the rate of operations of computing systems has improved
drastically but we have noticed relatively smaller improvement in the rate of
data transfers. The current computing systems face bottleneck due to the large
volume of data transfers. One of the promising approaches to solve  this problem
is to design algorithms which minimizes the data transfers. The goal of this course
is to present a variety of such algorithms for matrix and tensor computations.
</p>


<p>
  The course will also discuss various approaches to compute communication lower
  bounds (that determine how much data transfers are required) for different matrix
  and tensor computations. Establishing communication lower bounds helps one to
  identify efficient algorithms that exactly attains the bounds.
</p>
<p>
 Tensors are multi-dimensional arrays and arise in several domains, e.g., data
 mining, neurosciences, quantum computing, molecular dynamics and computer vision.
 <!--The course will also discuss how tensors are used to analyze multi-dimensional
 data sets. -->
 The course will also present how to extend data-aware approaches for matrix computations
 to tensors.
</p>





<!--
This course focuses on tensor decompositions as a tool to analyze multidimen-
sional data sets. After taking the course, students will be able to describe
tensor notation and various tensor decompositions, apply the decompositions
to different types of data using existing software, evaluate results and interpret
them when appropriate, analyze and evaluate existing algorithms for computing
tensor decompositions, and design new algorithms for related problems. Stu-
dents will program in MATLAB and/or Python. Background in numerical lin-
ear algebra, numerical optimization, or basic statistical analysis (e.g., principle
component analysis) will be helpful but not required.
-->

<i>Prerequisite:</i> Background in algorithms and their complexity analysis will be helpful but not required.

<!--

The project can be done individually or in groups of 2 and should either be
connecting your research to topics in this class or digesting a topic of interest
related to this class. The main output of the project is a report (in ACM format:
https://www.acm.org/publications/proceedings-template) and a presen-
tation to the class at the end of the semester. Projects must include theoretical
analysis of a parallel algorithm or a parallel implementation (or both). They
may focus on parallel computing pedagogy, along with some artifact (such as a
lesson plan, assignment scaffolding, and/or demonstration).

-->

<!-- Welcome to my course! -->

</body>
</html>
