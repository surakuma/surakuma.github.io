\documentclass[a4paper,11pt]{article}

\usepackage[light,math]{iwona}
\usepackage{fullpage}
\usepackage[utf8]{inputenc}
\usepackage[american]{babel}
\usepackage{amsfonts,amsmath,wasysym} %% Additional math chars
\usepackage{marvosym}
\usepackage{eurosym}

\usepackage{booktabs}
\usepackage{colortbl}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{eurosym}

\usepackage{etoolbox}
\patchcmd\section{2.3ex}{1.8ex}{}{}

%%\usepackage[backend=bibtex,maxbibnames=99,
%%	sortcites=true,
%%	doi=false,url=false]{biblatex}
%\addbibresource{submission.bib}
\usepackage{tikz}
\usepackage{tikzscale}
\usetikzlibrary{matrix}
\usetikzlibrary{fit}
\usetikzlibrary{trees}
\usetikzlibrary{backgrounds}
\usetikzlibrary{patterns}
\usetikzlibrary{calc}
\usetikzlibrary{decorations.pathreplacing}
\usetikzlibrary{arrows}
\usetikzlibrary{matrix}
\usetikzlibrary{trees}
\usetikzlibrary{positioning}
\usepackage{mdframed}


\input{./tensor_header}
\newcommand{\X}{\T{X}}
\newcommand{\Y}{\T{Y}}

\definecolor{pastelgreen1}{rgb}{0.47, 0.87, 0.47}
\definecolor{pastelgreen}{rgb}{0, 1, 0}

\definecolor{orange1}{RGB}{242, 142, 30}
\definecolor{orange2}{RGB}{245, 165, 77}
\definecolor{blue1}{RGB}{43, 114, 178}
\definecolor{blue2}{RGB}{76, 147, 212}
\usepackage[tight,footnotesize]{subfigure}

\usepackage[bookmarks=true,
bookmarksnumbered=true,
bookmarksopen=false,
plainpages=false,
pdfpagelabels,
colorlinks]{hyperref}

\definecolor{anrblue}{rgb}{0,0.2,0.4}
\definecolor{anrviolet}{rgb}{0.5,0,0.5}

\definecolor{pdfurlcolor}{rgb}{0,0,0.6}
\definecolor{pdfcitecolor}{rgb}{0,0.6,0}
\definecolor{pdflinkcolor}{rgb}{0.6,0,0}
%%
%%\usepackage[colorlinks=true,citecolor=pdfcitecolor,urlcolor=pdfurlcolor,linkcolor=pdflinkcolor,pdfborder={0 0 0}]{hyperref}


%%\hypersetup{
%%	citecolor=anrblue,              % color of cite links
%%	pagecolor=anrblue,         % color of page links
%%	menucolor=anrblue,         % color of Acrobat Reader menu buttons
%%	urlcolor=anrblue,       % color of page of \url{...}
%%	linkcolor=anrblue,
%%	urlbordercolor=red,% hyperlink borders will be red
%%	pdfborderstyle={/S/U/W 1}% border style will be underline of width  % 1pt
%%}

\hypersetup{
	citecolor=pdfcitecolor,              % color of cite links
	pagecolor=anrblue,         % color of page links
	menucolor=anrblue,         % color of Acrobat Reader menu buttons
	urlcolor=pdfurlcolor,       % color of page of \url{...}
	linkcolor=pdflinkcolor,
	urlbordercolor=red,% hyperlink borders will be red
	%%	pdfborderstyle={/S/U/W 1}% border style will be underline of width  % 1pt
}

\makeatletter
\Hy@AtBeginDocument{%
	\def\@pdfborder{0 0 1}% Overrides border definition set with colorlinks=true
	\def\@pdfborderstyle{/S/U/W 0.5}% Overrides border style set with colorlinks=true
	% Hyperlink border style will be underline of width 1pt
}
\makeatother

\ifxetex
\usepackage{fontspec}
\usepackage{fontawesome}
\defaultfontfeatures{Mapping=TeX-text}
\defaultfontfeatures{Ligatures=NoCommon}
\let\sfdefault\rmdefault
\setmainfont{FreeSerif}
\setromanfont{FreeSerif}
\newfontfamily\sectionfont[Color=anrblue]{DejaVu Sans}
\newfontfamily\subsectionfont[Color=anrblue]{DejaVu Sans}
\newfontfamily\tocsectionfont[Color=anrblue]{DejaVu Sans}
\newcommand\linksym{\faExternalLink}
\else
\newcommand\sectionfont{\color{anrblue}\normalfont\fontsize{14}{14}\bfseries}
\newcommand\subsectionfont{\color{anrblue}\normalfont\fontsize{12}{12}\bfseries}
\newcommand\tocsectionfont{\color{anrblue}\normalfont}
\newcommand\linksym{\Mundus}
\fi


\usepackage{color,xspace,paralist}
\definecolor{blue}{rgb}{0,0,1}
\newcommand{\blue}[1]{{\color{blue} #1}}

% Comment/uncomment the next lines to remove the guidelines

\newcommand{\gl}[1]{{\color{blue} \emph{#1}}}
\renewcommand{\gl}[1]{}
\newcommand{\bora}[1]{{\color{magenta} \emph{#1}}}
%\renewcommand{\bora}[1]{}
\newcommand{\sk}[1]{{\color{blue} \emph{#1}}}
%\renewcommand{\sk}[1]{}

\newcommand{\todo}[1]{{\color{red}\rule[-.1cm]{.4cm}{.4cm}~~{
			\color{red}{TODO: #1}}}\xspace}


\newcommand{\link}[2]{\href{#2}{#1\linksym}\xspace}


\newcommand*{\titleSK}{\begingroup 
	\centering 
	\begin{mdframed}[roundcorner=10pt,linewidth=1pt,leftmargin=10,rightmargin=10,shadow=true]%
		\vspace*{0.2\baselineskip}
		\centering
		{\Large \sc SCATE: SCAlable Tensor dEcompositions for data analytics}\\[0.1cm]
		%%        /STINT
		%%        {\LARGE \sc to enhance Low-Rank Compression}\\
		%		{\large \sc (Décompositions de tenseurs évolutives pour l'analyse de données)}\\[0.1cm]
		{\small CES46 $>$ Axe E.05 $>$ Calcul haute performance, Modèles numériques, simulation, applications}\\[0.1cm]
		{\normalsize Coordinated by: {\sc Suraj Kumar}\hfill   AAPG 2026 / JCJC 48 months}
		%		{\Large \sc Suraj Kumar, {\sc ROMA} project-team, {\sc Inria Lyon}}
		%%		{\normalsize AAPG 2023 / JCJC 48 months / Budget 283K\euro\bora{no need for budget here}}
		\vspace*{0.2\baselineskip}
	\end{mdframed}
	%%	  \vspace*{0.0cm} 
	%	\begin{center}
	%		\vspace*{0.025\baselineskip}
	%		{\Large \sc Suraj Kumar, {\sc ROMA} project-team, {\sc Inria Lyon}}
	%	\end{center}
	\endgroup}

\usepackage{fancyhdr}
\pagestyle{fancy}
\rhead{}
\lhead{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0.4pt}
\lfoot{S. Kumar, ANR JCJC 2026, SCATE}
\rfoot{\thepage}
\cfoot{}


%%\bibliography{scate}

\begin{document}
	%\thispagestyle{plain}
	%\vspace{3cm}
	\titleSK
	
	
	
	%%Preproposals must fulfil the two main evaluation criteria : « Quality and scientific aim » and « Organisation and implementation of the project ». Applicants are advised to consult the AAPG2023 guide for further information about different sub-criteria related to the chosen funding instrument. No budget information is required in the scientific document, given that no sub-criteria is linked to budget information in step 1.
	%%I. Pre-proposal’s context, positioning and objective(s)
	%%This paragraph refers to the evaluation criterion « Quality and scientific aim ». The following information should be detailed here:
	%%
	%%Project’s objectives and research hypotheses;
	%%Position of the project as it relates to the state of the art;
	%%Methodology to reach the scientific objectives of the project, detailed description of the intended method(s), including its disciplinary coverage (mono-trans-inter-disciplinary) ;
	%%Added-value in terms of scientific contribution, concerning the object, the research issue, the methodology ; added-value in terms of knowledge production;
	%%Ability of the project to address the research issues covered by the chosen research theme (cf. §G. Scientific themes covered by the Generic Call for Proposals 2023, in the call text).
	%%
	%%The criterion « Quality and scientific aims» will be the determining one: only the projects having received an « A » will proceed to the second step of the evaluation process.
	%%\todo{Presently I look for only high level suggestions.}
	\vspace*{-0.5cm}\section{Context, positioning and objectives}
	
	%%\todo{Why to do tensor decompositions for data analytics on large computers?}
	
	%%Tensors are multi dimensional arrays and arise in several domains, e.g., quantum molecular dynamics, data
	%%mining, neurosciences and computer vision. My focus will be on developing parallel and scalable algorithms for tensor
	%%computations and implementing them for modern HPC systems. The principal challenges are high computational and data
	%%transfer costs of these operations, limited parallelism exposed by most existing tensor data structures and algorithms, and
	%%little (or negligible) architecture knowledge in the current approaches. My research proposal is carved along solving (or
	%%mitigating) these challenges and will allow one to work efficiently with tensors on current and future computing systems.
	
	%%\todo{More applications}
	
	
	
	
	%	Clarity of research objectives and hypotheses
	%	Clarity of research objectives and hypotheses
	%	ÿ Scientific ambition of the project and positioning in relation to the state of the art
	%	ÿ Suitability and relevance of the methods implemented
	%	ÿ Suitability of the project to the chosen scientific axis
	
	%Contribution of the project to the coordinator's responsibility and the development of his/her team
	
	%Context, positioning and objectives of the pre-proposal (in relation to the
	%evaluation criterion “Quality and scientific ambition”)
	%ÿ Are the research objectives and hypotheses clearly described?
	%ÿ What is the positioning of the project in relation to the state of the art? (See “Bibliography” section of the writing framework)
	%ÿ Is the methodology for achieving the project objectives precisely described? Are these methods adequate?
	%ÿ What is the added value of the project in terms of scientific contribution, whether in terms of object, problem and methodological
	%approach, and added value in terms of knowledge production?
	%ÿ Does the project correctly justify its positioning in relation to the research issues of the chosen scientific axis?
	%
	
	%coordinator presented? Does he/she have previous experience in the field covered by the pre-proposal? Is his/her position
	%within his/her laboratory or future host laboratory for at least the duration of the project explained? Is his/her level of
	%involvement mentioned? Is it consistent with the objectives of the project and his/her responsibility for coordinating the
	%project?
	%ÿ Is the team assembled around the project presented? Does it present the complementary skills needed to achieve the
	%objectives?
	%	
	More than 403 million terabytes of data is produced every day~\cite{data-size-2025}. Analyzing such massive data is essential to extract valuable insights and make informed decisions. To accomplish this, it is crucial to design parallel and scalable approaches that efficiently utilize modern computing systems. Tensors are multi-dimensional arrays and used to store data in several domains~\cite{KB-SIAM-2009}, e.g., data mining, neuroscience and computer vision. Tensor decompositions help to identify inherent structure of data, achieve data compression and enable various ways of data analysis. Tensors are also used as operators to solve problems in applied mathematics, chemistry, and machine learning~\cite{KB-SIAM-2009,NPOV-NIPS-2015}.
%	Working with tensors is challenging as the computational effort and memory requirements grow exponentially with the number of dimensions. It is therefore necessary to work with patterns of the tensor data. Using low dimensional structure of high dimensional data is a powerful approach in this context. Most tensor decompositions represent data in low-dimensional structures for efficient analysis, manipulation, and storage~\cite{KB-SIAM-2009}.	
	Working with tensors is challenging as the computational effort and memory requirements grow exponentially with the number of dimensions. It is therefore necessary to exploit patterns in the tensor data. Leveraging the low-dimensional structure of high-dimensional data is a powerful approach in this context. Most tensor decompositions represent data in low-dimensional structures for efficient analysis and manipulation~\cite{KB-SIAM-2009}.
	
	%	Most tensor decompositions represent data in its low dimensional structures, that allow one to perform analysis and manipulation efficiently~\cite{KB-SIAM-2009}.
%	\bora{that 403M terabyte data are not all for tensors. If you have numbers or a rough estimate, when you list the "problems in applied mathematics..., you can tie it to that number."}
	
	
	
	%%\sk{History of CP: Polyadic (1927)-->Canonical decomposition/PARAFAC (1970) --> CP(2000) --> Canonical Polyadic (2010)}	
	%%	\bora{I think Canonical polyadic (or CP) is the shorted form; I do not know if the word ``canonical'' is a name on its own} 
	CP (also known as Canonical Polyadic or CANDECOMP or PARAFAC) and Tucker are the widely used tensor decompositions in the literature for data analytics. Both decompositions can be viewed as high order generalization of Singular Value Decomposition (SVD). CP decomposition is used to understand the latent components of the data, while Tucker decomposition is considered to be more appropriate for compression and multi-modal data analysis~\cite{KB-SIAM-2009}.
	
	\vspace*{-0.15cm}\begin{figure}[htb]
		\begin{center}
			\subfigure[CP decomposition.]{
				\begin{tikzpicture}[scale=0.23, every node/.style={transform shape}]
				
				\path (-2,0,-7) -- (2,0,7);
				
				\pgfmathsetmacro{\cubex}{4}
				\pgfmathsetmacro{\cubey}{4}
				\pgfmathsetmacro{\cubez}{4}
				\draw[blue,fill=pastelgreen] (0,0,0) -- ++(-\cubex,0,0) -- ++(0,-\cubey,0) -- ++(\cubex,0,0) -- cycle;
				\draw[blue,fill=pastelgreen] (0,0,0) -- ++(0,0,-\cubez) -- ++(0,-\cubey,0) -- ++(0,0,\cubez) -- cycle;
				\draw[blue,fill=pastelgreen] (0,0,0) -- ++(-\cubex,0,0) -- ++(0,0,-\cubez) -- ++(\cubex,0,0) -- cycle;
				
				\node[draw=none, text=black, scale=4] at (2,-2.25,-3) {$=$};
				\pgfmathsetmacro{\smallwidth}{0.5}
				\draw[blue,fill=pastelgreen] (\cubex+2,0,0) -- ++(-\smallwidth,0,0) -- ++(0,-\cubey,0) -- ++(\smallwidth,0,0) -- cycle;
				\draw[blue,fill=pastelgreen] (\cubex+2 +\cubex + 0.5,0.75,0) -- ++(-\cubex,0,0) -- ++(0,-\smallwidth,0) -- ++(\cubex,0,0) -- cycle;
				\draw[blue,fill=pastelgreen] (\cubex+2,0.5,0) -- ++(-\smallwidth,0,0) -- ++(0,0,-\cubez) -- ++(\smallwidth,0,0) -- cycle;
				
				\node[draw=none, text=black, scale=4] at (2+\cubex+3.8,-2.25,-3) {$+$};
				
				\draw[blue,fill=pastelgreen] (\cubex+2.5 + \cubex+2,0,0) -- ++(-\smallwidth,0,0) -- ++(0,-\cubey,0) -- ++(\smallwidth,0,0) -- cycle;
				\draw[blue,fill=pastelgreen] (\cubex+2.5+\cubex+2 +\cubex + 0.5,0.75,0) -- ++(-\cubex,0,0) -- ++(0,-\smallwidth,0) -- ++(\cubex,0,0) -- cycle;
				\draw[blue,fill=pastelgreen] (\cubex+2.5+\cubex+2,0.5,0) -- ++(-\smallwidth,0,0) -- ++(0,0,-\cubez) -- ++(\smallwidth,0,0) -- cycle;
				
				\node[draw=none, text=black, scale=4] at (2+\cubex+5 + \cubex+ 4.25, -2.25,-3) {$+$ $\cdots$ $+$};
				
				\draw[blue,fill=pastelgreen] (12 + \cubex+2.5 + \cubex+2,0,0) -- ++(-\smallwidth,0,0) -- ++(0,-\cubey,0) -- ++(\smallwidth,0,0) -- cycle;
				\draw[blue,fill=pastelgreen] (12+\cubex+2.5+\cubex+2 +\cubex + 0.5,0.75,0) -- ++(-\cubex,0,0) -- ++(0,-\smallwidth,0) -- ++(\cubex,0,0) -- cycle;
				\draw[blue,fill=pastelgreen] (12 + \cubex+2.5+\cubex+2,0.5,0) -- ++(-\smallwidth,0,0) -- ++(0,0,-\cubez) -- ++(\smallwidth,0,0) -- cycle;
				\end{tikzpicture}}$\qquad\qquad$
			\subfigure[Tucker decomposition.]{
				\begin{tikzpicture}[scale=0.23, every node/.style={transform shape}]
				\pgfmathsetmacro{\cubex}{4}
				\pgfmathsetmacro{\cubey}{4}
				\pgfmathsetmacro{\cubez}{4}
				\draw[blue,fill=pastelgreen] (-12,1,\cubez-2) -- ++(-\cubex,0,0) -- ++(0,-\cubey,0) -- ++(\cubex,0,0) -- cycle;
				\draw[blue,fill=pastelgreen] (-12,1,\cubez-2) -- ++(0,0,-\cubez) -- ++(0,-\cubey,0) -- ++(0,0,\cubez) -- cycle;
				\draw[blue,fill=pastelgreen] (-12,1,\cubez-2) -- ++(-\cubex,0,0) -- ++(0,0,-\cubez) -- ++(\cubex,0,0) -- cycle;
				\node[draw=none, text=black, scale=4] at (-8,-1,0) {$=$};
				
				\pgfmathsetmacro{\cubex}{2}
				\pgfmathsetmacro{\cubey}{2}
				\pgfmathsetmacro{\cubez}{2}
				\draw[blue,fill=pastelgreen] (0,0,0) -- ++(-\cubex,0,0) -- ++(0,-\cubey,0) -- ++(\cubex,0,0) -- cycle;
				\draw[blue,fill=pastelgreen] (0,0,0) -- ++(0,0,-\cubez) -- ++(0,-\cubey,0) -- ++(0,0,\cubez) -- cycle;
				\draw[blue,fill=pastelgreen] (0,0,0) -- ++(-\cubex,0,0) -- ++(0,0,-\cubez) -- ++(\cubex,0,0) -- cycle;
				
				\draw[blue,fill=pastelgreen] (-\cubex-1,1,0) -- ++(-\cubex,0,0) -- ++(0,-\cubey-2,0) -- ++(\cubex,0,0) -- cycle;
				\draw[blue,fill=pastelgreen] (\cubex+2+1,0,-\cubey) -- ++(-\cubex-2,0,0) -- ++(0,-\cubey,0) -- ++(\cubex+2,0,0) -- cycle;
				
				\draw[blue,fill=pastelgreen] (0,0,-\cubez-1) -- ++(-\cubex,0,0) -- ++(0,0,-\cubez-2) -- ++(\cubex,0,0) -- cycle;
				
				\path (-18,0) -- (8,0);
				\end{tikzpicture}}
			\vspace*{-0.25cm}\caption{CP and Tucker decompositions of a 3-dimensional tensor.\label{fig:CTdecompositions}}\vspace*{-0.5cm}
		\end{center}		
	\end{figure}
	
	Figure~\ref{fig:CTdecompositions} shows visual representations of both tensor decompositions for a 3-dimensional tensor. CP decomposition represents a tensor with the sum of rank one tensors. Whereas, Tucker decomposition represents a tensor with multiple factor matrices and a much smaller core tensor with the same number of dimensions as the original.
	%	 The number of dimensions for the core tensor and the original tensor are same. 
	As mentioned earlier, tensors are used to store data in several domains. For example, in neuroscience, a single trial to observe behaviors of neurons over time can be stored in a matrix and data of multiple trials in a 3-dimensional tensor. CP decomposition is a popular method to analyse such neuroscience data~\cite{WKV-Neuron-2018}.
	%%	\bora{this was said before}. 
	Similarly, a single experiment in combustion simulations or electron microscopy produces terabytes of data. For instance, tracking 64 variables on a 512$\times$512$\times$512 three-dimensional spatial grid for 128 time steps in a simulation requires to store $2^{40}$ entries. It is very difficult to transfer and analyze data of such experiments. Tucker decomposition is an appealing practice to compress such data before different types of analysis can be performed~\cite{ABK-IPDPS-2016}.
	
	
	%%Computations involving Tucker-format tensors, such as tensor inner products, often require far fewer operations than with their full-format, dense representations. As a result, the Tucker decomposition is often used as a dimensionality reduction technique before other types of analysis are done.
	
	
	
	%    Therefore, we focus on CP and Tucker decompositions that are widely used for data analytics.
	
	
	
	%%	Recent advances in computing architectures enable us to witness many high performance computing (HPC) systems which perform more than $1$ million billion operations per second -- \href{https://www.olcf.ornl.gov/frontier}{Frontier} at ORNL and \href{https://www.genci.fr/en/our-computers}{Adastra} at GENCI, for example. Such systems have a large number of computing units and enable us to tackle some of the science and societal issues which was not possible before. Traditionally, there has been a great emphasis on developing algorithms which minimize the number of computations. In the last few decades, the rate of computations in these systems has improved drastically, but we have noticed relatively smaller improvement for the rate of data movement. The current HPC systems face bottleneck due to the large volume of communications~\cite{DOE-Report-2014}. Thus it is extremely important to develop algorithms which take communication costs into account. This approach also reduces energy consumption of the computations. GPUs deliver increased processing capabilities and superior energy efficiency compared to CPUs. Therefore, they have become a crucial element of many HPC systems over the past decade. The SCATE project addresses communication costs and scalability of tensor decompositions on the modern HPC systems. More precisely, the high level aim of the project is to devise communication optimal tensor decomposition algorithms which scale well on both homogeneous and heterogeneous systems. Establishing communication lower bounds is also an important part of the project as it helps one to identify the more precise parallel algorithms that match the lower bounds.
	
	
	%	The data generated by many experiments is so big that it is impossible to perform a CP/Tucker decomposition without parallel computations.
	The data generated by many experiments in areas such as neuroscience, combustion simulation and hyperspectal imaging is so large that performing a CP or Tucker decomposition becomes infeasible without parallel computation.
	%	The data produced by large-scale experiments in areas such as neuroscience, hyperspectral imaging, and recommender systems is so large that CP or Tucker decomposition becomes infeasible without parallel computation.
	Therefore, it is important to focus on parallel algorithms for both decompositions.
	Recent advances in computing architectures have led to the development of parallel high performance computing (HPC) systems equipped with a large number of computational units.
	%	Thanks to recent advances in architectures, we witness many parallel high performance computing (HPC) systems with a large number of computational units
	%	which perform more than $1$ million billion operations per second 
	-- \href{https://asc.llnl.gov/exascale/el-capitan}{El Capitan} at LLNL and \href{https://dci.dci-gitlab.cines.fr/webextranet/architecture}{Adastra} at CINES, for example. 
	%	In the last few decades, the rate of computations has improved drastically, but we have noticed relatively smaller improvement in the rate of data movement. 
	While computational performance has advanced rapidly over the past few decades, improvements in data movement rates have been comparatively limited.
	The current HPC systems face bottleneck due to the large volume of data transfers~\cite{DOE-Report-2014}. Thus it is crucial to take communication costs into account while designing parallel algorithms. In doing so, one also reduces energy consumption -- a must in today’s world facing growing environmental and sustainability challenges.
%	This approach also reduces energy consumption of the computations\bora{Maybe "In doing so, one also reduces the energy consumption, a must in today's ust in today’s world facing growing environmental and sustainability challenges."}. 
	GPUs provide increased processing capabilities and superior energy efficiency compared to CPUs, making them a crucial component of HPC systems over the past decade.
	%	Developing only CPU based approaches may ignore too much computation power on such systems and may result in poor efficiency. Therefore, it is important to focus on both homogeneous and heterogeneous systems.
	Developing CPU-only approaches may overlook a significant portion of the computational power in such systems, leading to poor efficiency. Therefore, it is important to focus on both types of processing units while developing algorithms for these systems
%	 \bora{alternative: while developing algorithms for these systems.} in these sytems.
	The SCATE project addresses parallelization, communication costs and scalability of tensor decompositions on the modern HPC systems. More precisely, the high level aim of the project is to devise parallel and communication optimal tensor decomposition algorithms which scale well on both homogeneous and heterogeneous systems. Establishing communication lower bounds is also an important part of the project as it helps one to devise efficient parallel algorithms.
	
	
	
	Most existing tensor decomposition algorithms work with matrix (2-dimensional) representations of tensors at each step and rely on the parallelization of matrix operations. This approach neglects multi-dimensional properties of tensors and may not perform the computation efficiently. We focus on improving the performance of Tucker and CP decomposition algorithms by taking multi-dimensional properties of tensors into account.
	
	
	
	\vspace*{-0.35cm}\paragraph{Algorithms to compute Tucker decompositions:}
	Truncated higher-order SVD (HOSVD) is one of the popular algorithms for computing a Tucker decomposition, thanks to its quasi-optimal numerical approximation~\cite{VVM-2012}.
%	\bora{Cite? Vannieuwenhoven et al?}. 
%	the core tensor is computed with the full-format original tensor and multiple tall and skinny factor matrices\bora{finishign statement has awkward structure for me}.
	 In this algorithm, the core tensor is obtained using the full-format tensor and multiple tall-and-skinny factor matrices. 
	For a 3-dimensional tensor $\X$, computation of the core tensor $\Y$ can be expressed in tensor notation as $\Y = \X \times_1 {\Mn{A}{1}}^\Tra \times_2 {\Mn{A}{2}}^\Tra \times_3 {\Mn{A}{3}}^\Tra$, where 
	%$\X$ is the full-format 
	%representation of the original 
	%tensor,
	$\Mn{A}{k}$ is a tall-skinny factor matrix corresponding to mode $k$, and $\times_k$ denotes the tensor-times-matrix (TTM) operation in the $k$th mode~\cite{KB-SIAM-2009}. This collective operation is known as the Multi-TTM computation~\cite{ABGKR-SIMAX-2022} and is one of the main bottleneck of the HOSVD algorithm. One approach to perform this computation is \emph{in~sequence}, i.e., $\Y = ((\X \times_1 {\Mn{A}{1}}^\Tra )\times_2 {\Mn{A}{2}}^\Tra) \times_3 {\Mn{A}{3}}^\Tra$. Another approach is to work with the inputs \emph{all~at~once}, i.e., $\Y_{ijk} = \sum_{lmp}\X_{lmp}\cdot\Mn{A}{1}_{li}\cdot \Mn{A}{2}_{mj}\cdot \Mn{A}{3}_{pk}$.
	%%	\bora{why * and $\times$} 
	Daas et al.~\cite{ABGKR-SIMAX-2022} show that the latter approach, which takes multi-dimensional properties of tensors into account, reduces communication significantly compared to the sequence approach for small and moderate number of processors. However there is not any clear winner for all settings. One can achieve better gains with a hybrid method that combines the strengths of both approaches. This perspective is not explored in~\cite{ABGKR-SIMAX-2022}.
	%	We can obtain better gains by a hybrid method which combines the best of both approaches. 
	Furthermore, the amount of operations for the Multi-TTM computation depends on how factor matrices are processed with the input tensor. It is also important to model the computation-communication tradeoff in the combined hybrid method such that the overall completion time of the Multi-TTM is minimized.
	
	In addition, HOSVD algorithm also computes SVD for each mode to obtain the corresponding factor matrix. Optimal data distributions to perform SVDs and the Multi-TTM computation may not be compatible and may require to perform extra communication. As SVD is expensive, it is also important to consider alternatives, such as randomized SVD, for computing factor matrices. These issues must be addressed to achieve optimal completion time for the entire HOSVD algorithm.
	%	These topics need to be addressed so that one can achieve the optimal completion time for the complete HOSVD algorithm. 
	%	At last, our goal is to determine communication lower bound and communication-computation tradeoff for the complete HOSVD algorithm and devise a method which achieves the optimal completion time. 
	
	%	it is also look at other alternatives like randomized SVD to compute factor matrices.
	
	
	
	
	%Considering optimal data distributions for only one approach may induce significant data movements for the other approach. Using optimal data distributions for both approaches may not be compatible or require significant data movement during the transition of the approach. 
	
	%%When the computational costs of the matrix SVDs are reduced using randomization, Multi-TTM becomes the overwhelming bottleneck computation [22, 25].
	
	%% Talk about MTTKRP
	
	\vspace*{-0.35cm}\paragraph{Algorithms to compute CP decompositions:}
	Computing a CP decomposition involves solving a nonlinear optimization problem to minimize the approximation error. The workhorse algorithm to compute this decomposition uses an alternating least squares approach. This works in multiple iterations. For a $d$-dimensional decomposition, in each iteration, $d$ matricized-tensor times Khatri-Rao product (MTTKRP) computations are performed. In this computation, a matrix representation of the original tensor is multiplied with the Khatri-Rao product
%	\bora{since Kahtri-Rao is note defined, in an understandable math?} 
	of $d-1$ factor matrices. This is the bottleneck computation of the algorithm. 
	Ballard et al.~\cite{BNR-IPDPS-2018} show that the working
	%%	\bora{did not understand}\sk{I added more details.}
	with all the inputs at once without forming intermediates reduces communication costs significantly compared to the procedure where the Khatri-Rao product is computed first and the intermediate output is multiplied with a matricized representation of the original tensor. Certain operations can be reused among all MTTKRPs of a single iteration. But, their approach restricts the reuse of operations as intermediates are not formed. The amount of operations in the MTTKRP computation also depends on how factor matrices are processed with the original tensor.
	%%	different inputs are grouped in the procedure.
	It is important to study tradeoff among communications, computations and reuse of intermediate results, and design a method that achieves optimal completion time.
%	Addressing these issues is necessary to ensure each iteration of the algorithm achieves optimal completion time.
%	\bora{the last statement is somehow redundant/repeating the one just before.}
	%	Similar to the previous plan, at last, our goal is to devise a method for a single iteration of the algorithm which achieves optimal completion time.
	%	Another state-of-the-art approach to compute a CP decomposition is based on gradients. MTTKRP is also the bottleneck computation for this approach. Hence, improving the performance of MTTKRP will also accelerate gradient-based approach to compute the decomposition.
	
	
	
%	\vspace*{-0.35cm}\paragraph{Our approach to challenges:} As mentioned earlier, computations and communication costs of Multi-TTM and MTTKRP depend on how factor matrices are processed
%%	\bora{this use of "operate" is not natural for me.} 
%	with the input tensor. If we do not select it carefully, their completion times may be very far from the optimal ones. Even when we know how we want to perform the computations, combining \emph{all~at~once} and \emph{in~sequence} approaches, using one after the other, in a straightforward way will only work if data distributions of inputs and temporaries between both approaches are compatible. However we cannot expect any guarantees with respect to the optimal communication/computation costs. Therefore, in order to take benefits of both \emph{all~at~once} and \emph{in~sequence} approaches, it is important to analyze all possible ways to combine them. We will study how to to perform 3 and 4-dimensional Multi-TTM and MTTKRP computations in detail as the number of ways are limited. After that, we will generalize our findings and create a dynamic programming based approach to determine how to perform d-dimensional computations.
%	
	
	
	\vspace*{-0.35cm}\paragraph{Objectives:} The goal of the SCATE project is to develop Tucker and CP decomposition algorithms that scale efficiently on modern computing systems.
	The project first studies tradeoff among computations, communications and data reuse for the existing algorithms and proposes new methods whose completion times are optimal for homogeneous systems. After that, the proposed methods will be implemented and tested with real-world data-sets from neuroscience and combustion simulations on  more than 5,000 cores and/or 512 nodes of \href{https://www.genci.fr/en/our-computers}{GENCI computers}. This implementation will also be used to accelerate hyperspectral data analysis in astrophysics.
%	and brain-computer interface data analysis in electrophysiology. 
	The project also extends our framework for heterogeneous systems composed of CPUs and GPUs.
	
	With the help of other researchers from tensor community, the project also plans to setup a public repository to store dense tensors of real applications. We will add all the used real-world tensors to that repository. We will also add code snippets of real applications that generate dense tensors, such as correlation functions.
	

	
	
	
	\vspace*{-0.35cm}\paragraph{Our approach:} As mentioned earlier, the computations and communication costs of Multi-TTM and MTTKRP depend on how we perform them, i.e., how matrices are processed with the input tensor. If we do not select it carefully, their completion times may be very far from the optimal ones. Even when we know how we want to perform the computations, combining all at once and sequence approaches, using one after the other, in a straightforward way will only work if data distributions of inputs and temporaries between both approaches are compatible. However we can not expect any guarantees with respect to the optimal communication/computation costs. Considering optimal data distributions for only one approach may induce significant data movements for the other approach. Using optimal data distributions for both approaches may not be compatible or require significant data movement during the transition of the approach. Therefore, in order to take benefits of both \emph{all~at~once} and \emph{in~sequence} approaches, it is important to study all possible ways to combine them. More precisely, we will i) analyze communication costs for all possible ways to perform both computations, ii) investigate tradeoff among amount of operations, communications and data reuse, and iii) design communication optimal parallel algorithms.
	
	We will study $3-$ and $4$-dimensional computations in detail as the number of ways is limited. Subsequently, we will generalize our findings and develop a dynamic programming based approach for $d$-dimensional computations. After performing a detailed study of Multi-TTM and MTTKRP, we will design parallel algorithms to minimize the overall completion times of both decompositions.
	
	
	%	We will implement our algorithms for homogeneous systems and test them on various datasets.
	
	We will implement our parallel algorithms for homogeneous systems using MPI . All the communications would be performed with collectives. This is a simple and popular strategy to minimize communication for many linear algebra computations~\cite{ABK-IPDPS-2016}. We plan to determine processor grid dimensions analytically based on the components of communication lower bounds. We will equate the communication cost expressions of all matrices and tensors to their respective lower bounds, and determine solutions that satisfy all constraints, especially those involving dominant terms. 	Since MPI collectives rely on global synchronization, they may not efficiently utilize all resources of heterogeneous systems. Therefore, we will develop task-based parallel algorithms for such systems, enabling efficient execution with runtime systems such as \href{https://starpu.gitlabpages.inria.fr}{StarPU}.
	
	
	%	As MPI collectives are based on global synchronization, they may not efficiently utilize all resources of a heterogeneous system. Therefore, we will design our parallel algorithms in task-based structure for heterogeneous systems. This will allow us to run them efficiently with popular runtime systems such as \href{https://starpu.gitlabpages.inria.fr}{StarPU}.
	
	
	
	Tensor Train is another popular tensor representation. This is very well suited to work with high dimensional tensors and used often in molecular and quantum simulations. However, this has limited use in data analytics as it is hard to interpret its different components. Therefore, we focus on CP and Tucker decompositions in this project and leave Tensor Train decomposition for future work. 
	
	
	%	\paragraph{Objectives:} The goal of the SCATE project is to devise Tucker and CP decomposition algorithms which scale well on the modern computing systems. The project first studies tradeoff among computations, communications and data reuse for the existing algorithms and proposes new methods whose completion times are optimal for homogeneous systems. After that, the proposed methods will be implemented and tested with various real-world data-sets on \href{https://www.genci.fr/en/our-computers}{GENCI computers}. Significant amount of performance is produced by accelerators for the present HPC systems, including many at GENCI. So developing only homogeneous algorithms ignores too much computation power and may result in poor efficiency on heterogeneous systems. The project does address this concern and extends our framework for heterogeneous systems with CPUs and GPUs.
	
	
	
	%%	There is very less work on communication guarantees for linear algebra computations on heterogeneous system. One ambitious aspect of the project is to extend our framework for heterogeneous systems with CPUs and GPUs. It requires us to model different processing and transfer capabilities of different units and their network topology with the aim to minimize the overall completion time.
	
	
%	
%	\vspace*{-0.35cm}\paragraph{Tasks:} The objective of the project will be achieved through two tasks. 
%%	\bora{there is surely a management and dissemination task; maybe indicate that you do not cover it here. A collection/repository if you are going to include in the longer document will go in that task.}
%	\textbf{Task A} focuses on homogeneous systems and \textbf{Task B} targets heterogeneous systems. \textbf{Task A} is further subdivided into six main work packages. \textbf{WPA1} aims to obtain communication lower bounds for algorithms to compute Tucker and CP decompositions. \textbf{WPA2} analyzes tradeoff among computations, communications and data reuse for the tensor decomposition algorithms. \textbf{WPA3} designs new algorithms which achieve optimal completion time. \textbf{WPA4} implements the proposed algorithms for distributed memory homogeneous systems and validates the performance improvement on more than 5,000 cores and/or 512 nodes of \mbox{\href{https://www.genci.fr/en/our-computers}{GENCI computers}}. \textbf{WPA5} studies the numerical robustness of the proposed algorithms.
%	%%	Performing mixed precision arithmetic is a promising direction to improve performance of many scientific computations. 
%	\textbf{WPA6}, towards the end of the project, explores how to apply mixed precision arithmetic to further improve our algorithms.
%	
%	
%	Similarly, \textbf{Task B} is further subdivided into four main work packages. \textbf{WPB1} models
%	communication costs among different processing units for a single node composed of CPUs and GPUs. \textbf{WPB2} aims to obtain communication lower bounds of tensor decomposition algorithms and \textbf{WPB3} proposes new algorithms which achieve optimal completion times for a single heterogeneous node. \textbf{WPB4} extends the proposed framework to multiple heterogeneous nodes.
%	
%	
	
	%	We will begin with \textbf{Task A}. Our framework for \textbf{WPA1} and \textbf{WPA2} will be ready within a year. We will also have good understanding of structure of computations and communications for the decomposition algorithms by then. We will start \textbf{Task B} at this point.
	
	
	\vspace*{-0.15cm}\paragraph{Dissemination and new collaborations:} We expect to publish the obtained results to the major venues (conferences/journals) of the field (SC, IPDPS, SIMAX, SISC). Furthermore we plan to organize a minisymposium on tensor computations at SIAM Conference on Computational Science and Engineering 2027. This will facilitate fruitful discussions with other tensor experts and users, and open avenues for potential collaborations.
%	Tensor operations are fundamental to multi-dimensional data analytics in various domains, such as neuroscience, scientific simulations, data mining, computer vision, and astrophysics. 
	The algorithms that will be developed in this project will be freely available. We will publish the code under a free license.
%	 The approval of this proposal will speed up our discussions with domain scientists and help us to establish new collaborations. 
	
	
	\vspace*{-0.25cm}\section{Consortium}
	
	
	\vspace*{-0.15cm}\paragraph{Scientific coordinator:}Suraj Kumar (PI) holds an Inria Starting Faculty Position since October 2022 in the ROMA Inria team, which is hosted at École Normale Supérieure de Lyon (ENS Lyon). He is an expert in tensor computations, communication avoiding algorithms and efficient utilization of resources on heterogeneous systems. He worked at Inria Paris from November 2019 to September 2022 as a postdoctoral researcher on the design of parallel and communication optimal algorithms for Multi-TTM computations and tensor-train decompositions. He was also a postdoctoral researcher at Pacific Northwest National Laboratory, USA from May 2018 to October 2019. He worked there on \href{https://www.exascaleproject.org/research-project/nwchemex}{NWChemEx} project, whose main goal was to run molecular simulations efficiently on exascale computers. He defended his thesis in April 2017 on Scheduling of Dense Linear Algebra Kernels on Heterogeneous Resources. 
	%	He has an active collaboration with G. Ballard of Wake Forest University, USA, who is an expert in the design of communication-efficient algorithms, that will be beneficial to the implementation of the project. 
	The PI will dedicate 75\% of his time on this project.
%	\bora{Maybe better to list, especially the post-docs,in reverse chronological order. }
	
	\vspace*{-0.25cm}\paragraph{Team:} The SCATE project will take place within the Inria ROMA team, in collaboration with other members of the team. In particular, L. Marchal (DR2, CNRS) will bring his expertise in memory-aware computations and B. Uçar (DR2, CNRS) is an expert in the design and implementation of efficient spase tensor algorithms on large-scale systems.
	%	The SCATE project includes L. Marchal (DR2, CNRS) and B. Uçar (DR2, CNRS) from the Inria ROMA team. B. Uçar will bring his expertise in tensor computations, while L. Marchal is an expert in memory-aware computations and the design of scheduling algorithms for heterogeneous resources.
	We ask for a PhD student, 24 months of a postdoctoral researcher and two master interns. The PhD student will work with the PI and B. Uçar (PhD co-advisor) on designing optimal algorithms for Tucker and CP decompositions on homogeneous systems. The master interns will study the numerical robustness of the proposed algorithms with the PI. The postdoctoral researcher will work with the PI and L. Marchal on extending the framework for heterogeneous systems, and will also help the PI to advise the PhD student. The PI has an active collaboration with G. Ballard of Wake Forest University, USA, who is an expert in the design of communication-efficient algorithms, that will be beneficial to the implementation of the project. 
	
	
	%	\vspace*{-0.25cm}\paragraph{Growth of the PI:}
	%	We expect to publish the obtained results to the major venues (conferences/journals) of the field (SC, IPDPS, SIMAX, SISC). Furthermore we plan to organize a minisymposium on tensor computations at SIAM Conference on Computational Science and Engineering 2027. This will allow us to start more collaborations and fruitful discussions. Tensor operations are fundamental to multi-dimensional data analytics in various domains, such as neuroscience, scientific simulations, data mining, computer vision, and astrophysics. The approval of this proposal certainly will speed up our discussions with domain scientists and help us to establish new collaborations. 
	%	
	
	
	
	%%\vspace*{1ex}
	\vspace*{-0.315cm}
	{\footnotesize
		\bibliographystyle{IEEEtranS}
		\bibliography{scate}
	}
	%\vspace*{-0.215cm}
	
	
	%	
	%\sk{	
	%    \begin{itemize}
	%%        \item Why we do not consider tensor train decomposition
	%        \item Mention applications from astrophysic and electrophysiology
	%        \item Rewording of the last paragraph
	%        \item What technical challenges associated with combining all-at-once and in-sequence approaches
	%        \item Types of datasets
	%        \item Real world applications
	%    \end{itemize}
	%}
	
	%\emph{Abstract:}
	%%
	%Tensors are multi-dimensional arrays and used to store data in several domains, e.g., data mining, neuroscience, astrophysics, scientific simulations and computer vision. Tensor decompositions help to identify inherent structure of data, achieve data compression and enable various ways of data analysis. The computational and memory requirements of tensor operations grow exponentially with the number of dimensions. It is paramount to devise parallel tensor decomposition algorithms that make effective utilization of the modern computing systems. The principal challenges are data transfer costs of tensor operations and limited parallelism exposed by most existing algorithms. This project aims at solving these challenges and proposing new decomposition algorithms which scale well on current and future computing systems. Finally, the proposed algorithms will be implemented for large scale distributed systems and evaluated on real-world tensors from neuroscience and combustion simulations. The implementation will also be used to accelerate hyperspectral data analysis in astrophysics and brain-computer interface data analysis in electrophysiology.
	%
	%
	%
	%
	%\emph{French Abstract:}
	%%Les tenseurs sont des tableaux multidimensionnels utilisés pour stocker des données dans plusieurs domaines, par exemple pour la fouille de données, en neurosciences, en astrophysique, dans les simulations scientifiques et pour la vision par ordinateur. Les décompositions de tenseurs permettent d'identifier la structure inhérente des données, de les compresser et de les analyser de diverses manières. Les besoins en calcul et en mémoire des opérations tensorielles augmentent de manière exponentielle avec le nombre de dimensions. Il est primordial de concevoir des algorithmes parallèles de décomposition de tenseurs qui utilisent efficacement les systèmes informatiques modernes.  Les principaux défis sont les coûts importants de transfert de données et le parallélisme limité de la plupart des algorithmes existants.  Ce projet vise à résoudre ces défis et à proposer de nouveaux algorithmes de décomposition qui s'adaptent bien aux systèmes informatiques actuels et futurs. Enfin, les algorithmes proposés seront implantés sur des machines de calcul distribuées à grande échelle et évalués sur des tenseurs provenant de divers domaines applicatifs. La mise en oeuvre sera également utilisée pour accélérer l'analyse des données hyperspectrales en astrophysique et l'analyse des données d'interface cerveau-ordinateur en électrophysiologie.
	%
	%Les tenseurs sont des tableaux multidimensionnels utilisés pour stocker des données dans plusieurs domaines, par exemple l'exploration de données, les neurosciences, l'astrophysique, les simulations scientifiques et la vision par ordinateur. Les décompositions de tenseurs permettent d'identifier la structure intrinsèque des données, de les compresser et de les analyser de diverses manières. Les besoins en calcul et en mémoire des opérations tensorielles augmentent de manière exponentielle avec le nombre de dimensions. Il est primordial de concevoir des algorithmes parallèles de décomposition de tenseurs qui utilisent efficacement les systèmes informatiques modernes. Les principaux défis sont les coûts de transfert de données des opérations tensorielles et le parallélisme limité exposé par la plupart des algorithmes existants. Ce projet vise à résoudre ces défis et à proposer de nouveaux algorithmes de décomposition qui s'adaptent bien aux systèmes informatiques actuels et futurs. Enfin, les algorithmes proposés seront implémentés et testés sur des systèmes distribués à grande échelle et évalués sur des tenseurs réels issus de la neuroscience et de simulations de combustion. L'implémentation sera également utilisée pour accélérer l'analyse des données hyperspectrales en astrophysique et l'analyse des données d'interface cerveau-machine en électrophysiologie.
	
	
	
	%Les tenseurs sont des tableaux multidimensionnels utilisés pour stocker des données dans plusieurs domaines, par exemple l'exploration de données, les neurosciences, l'astrophysique, les simulations scientifiques et la vision par ordinateur. Les décompositions de tenseurs permettent d'identifier la structure inhérente des données, de les compresser et de les analyser de diverses manières. Les besoins en calcul et en mémoire des opérations tensorielles augmentent de manière exponentielle avec le nombre de dimensions. Il est primordial de concevoir des algorithmes parallèles de décomposition de tenseurs qui utilisent efficacement les systèmes informatiques modernes. Les principaux défis sont les coûts de transfert de données des opérations tensorielles et le parallélisme limité exposé par la plupart des algorithmes existants. Ce projet vise à résoudre ces défis et à proposer de nouveaux algorithmes de décomposition qui s'adaptent bien aux systèmes informatiques actuels et futurs. Enfin, les algorithmes proposés seront mis en œuvre pour des systèmes distribués à grande échelle et évalués sur des tenseurs réels issus de la neuroscience et de simulations de combustion. La mise en œuvre sera également utilisée pour accélérer l'analyse des données hyperspectrales en astrophysique et l'analyse des données d'interface cerveau-ordinateur en électrophysiologie.
	
%	L'implémentation sera également utilisée pour accélérer l'analyse des données hyperspectrales en astrophysique.
	
\end{document}

